{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e5eec3-5e80-46f0-9eb3-94216915c65b",
   "metadata": {},
   "source": [
    "## Neo4j Import of GraphRAG Result Parquet files\n",
    "This notebook imports the results of the GraphRAG indexing process into the Neo4j Graph database for further processing, analysis or visualization.\n",
    "\n",
    "### How does it work?\n",
    "The notebook loads the parquet files from the output folder of your indexing process and loads them into Pandas dataframes. It then uses a batching approach to send a slice of the data into Neo4j to create nodes and relationships and add relevant properties. The id-arrays on most entities are turned into relationships.\n",
    "\n",
    "All operations use `MERGE`, so they are idempotent, and you can run the script multiple times.\n",
    "\n",
    "If you need to clean out the database, you can run the following statement\n",
    "```\n",
    "MATCH (n)\n",
    "CALL { WITH n DETACH DELETE n } IN TRANSACTIONS OF 25000 ROWS;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581aea5-dacb-4bd3-b96c-f45d84ba05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHRAG_FOLDER=\"output/20241002-135325/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eeee95f-e4f2-4052-94fb-a5dc8ab542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c15443-4acb-4f91-88ea-4e08abaa4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"siat-mic\"\n",
    "NEO4J_DATABASE=\"pskdemo\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d787bf7b-ac9b-4bfb-b140-a50a3fd205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batched_import(statement, df, batch_size=1000):\n",
    "#     \"\"\"\n",
    "#     Import a dataframe into Neo4j using a batched approach.\n",
    "#     Parameters: statement is the Cypher query to execute, df is the dataframe to import, and batch_size is the number of rows to import in each batch.\n",
    "#     \"\"\"\n",
    "#     total = len(df)\n",
    "#     start_s = time.time()\n",
    "#     for start in range(0,total, batch_size):\n",
    "#         batch = df.iloc[start: min(start+batch_size,total)]\n",
    "#         result = driver.execute_query(\"UNWIND $rows AS value \" + statement, \n",
    "#                                       rows=batch.to_dict('records'),\n",
    "#                                       database_=NEO4J_DATABASE)\n",
    "#         print(result.summary.counters)\n",
    "#     print(f'{total} rows in { time.time() - start_s} s.')    \n",
    "#     return total\n",
    "\n",
    "def batched_import(statement, df, batch_size=1000):\n",
    "    total = len(df)\n",
    "    start_s = time.time()\n",
    "    successful_batches = 0\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = df.iloc[start: min(start+batch_size, total)]\n",
    "        try:\n",
    "            result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n",
    "                                          rows=batch.to_dict('records'),\n",
    "                                          database_=NEO4J_DATABASE)\n",
    "            successful_batches += 1\n",
    "            print(f\"Batch {successful_batches} processed, counters: {result.summary.counters}\")\n",
    "        except:\n",
    "            print(f\"Error processing batch starting at row {start}:\")\n",
    "            # 根据实际需要执行的降级或者 校正逻辑\n",
    "    print(f'{total} rows processed in {time.time() - start_s} seconds.')    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb8ef0-90fe-4aab-812b-def8f62fd0ad",
   "metadata": {},
   "source": [
    "### Indexes and Constraints\n",
    "Indexes in Neo4j are only used to find the starting points for graph queries, e.g. quickly finding two nodes to connect. Constraints exist to avoid duplicates, we create them mostly on id's of Entity types.\n",
    "\n",
    "We use some Types as markers with two underscores before and after to distinguish them from the actual entity types.\n",
    "\n",
    "The default relationship type here is `RELATED` but we could also infer a real relationship-type from the description or the types of the start and end-nodes.\n",
    "\n",
    "* `__Entity__`\n",
    "* `__Document__`\n",
    "* `__Chunk__`\n",
    "* `__Community__`\n",
    "* `__Covariate__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed7f212e-9148-424c-adc6-d81db9f8e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique\n",
      "\n",
      "create constraint document_id if not exists for (d:__Document__) require d.id is unique\n",
      "\n",
      "create constraint entity_id if not exists for (c:__Community__) require c.community is unique\n",
      "\n",
      "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique\n",
      "\n",
      "create constraint entity_title if not exists for (e:__Entity__) require e.name is unique\n",
      "\n",
      "create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique\n",
      "\n",
      "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique\n"
     ]
    }
   ],
   "source": [
    "# create constraints, idempotent operation\n",
    "\n",
    "statements = \"\"\"\n",
    "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique;\n",
    "create constraint document_id if not exists for (d:__Document__) require d.id is unique;\n",
    "create constraint entity_id if not exists for (c:__Community__) require c.community is unique;\n",
    "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique;\n",
    "create constraint entity_title if not exists for (e:__Entity__) require e.name is unique;\n",
    "create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique;\n",
    "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique;\n",
    "\"\"\".split(\";\")\n",
    "\n",
    "for statement in statements:\n",
    "    if len((statement or \"\").strip()) > 0:\n",
    "        print(statement)\n",
    "        driver.execute_query(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b611db-03d4-4afc-ba9c-a801c3d26d91",
   "metadata": {},
   "source": [
    "## Import Process\n",
    "### Importing the Documents\n",
    "We're loading the parquet file for the documents and create nodes with their ids and add the title property. We don't need to store text_unit_ids as we can create the relationships and the text content is also contained in the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec93c92-499d-4ec6-bf3b-c34f74552600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501b15313a5b7a866056af4b22ac5fc0</td>\n",
       "      <td>10.1002_adfm.201705094.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a50ab37c5b0b5a68fecd1a8f2a80302e</td>\n",
       "      <td>10.1002_adma.201804547.md</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                      title\n",
       "0  501b15313a5b7a866056af4b22ac5fc0  10.1002_adfm.201705094.md\n",
       "1  a50ab37c5b0b5a68fecd1a8f2a80302e  10.1002_adma.201804547.md"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_documents.parquet', columns=[\"id\", \"title\"])\n",
    "doc_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd3d380-8710-46f5-b90a-04ed8482192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'labels_added': 102, 'nodes_created': 102, 'properties_set': 204}\n",
      "102 rows processed in 0.33764171600341797 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import documents\n",
    "statement = \"\"\"\n",
    "MERGE (d:__Document__ {id:value.id})\n",
    "SET d += value {.title}\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, doc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa9028-4b62-4a14-86be-fad56b0c77f3",
   "metadata": {},
   "source": [
    "### Loading Text Units\n",
    "We load the text units, create a node per id and set the text and number of tokens. Then we connect them to the documents that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "140b420e-045e-4c71-9f25-1a20c5b528bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bbce30e7dc572bce177cba82bc6037c0</td>\n",
       "      <td># Strong Self-Trapped Exciton Emission and Hig...</td>\n",
       "      <td>2000</td>\n",
       "      <td>[041bf644e7ec23fa052505c1edb4fac8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36fb9bc4eec29c1edde2cce78e0da6e5</td>\n",
       "      <td>the STE states and then to  ${^2}\\mathrm{F}_{...</td>\n",
       "      <td>2000</td>\n",
       "      <td>[041bf644e7ec23fa052505c1edb4fac8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  bbce30e7dc572bce177cba82bc6037c0   \n",
       "1  36fb9bc4eec29c1edde2cce78e0da6e5   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  # Strong Self-Trapped Exciton Emission and Hig...      2000   \n",
       "1   the STE states and then to  ${^2}\\mathrm{F}_{...      2000   \n",
       "\n",
       "                         document_ids  \n",
       "0  [041bf644e7ec23fa052505c1edb4fac8]  \n",
       "1  [041bf644e7ec23fa052505c1edb4fac8]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_text_units.parquet',\n",
    "                          columns=[\"id\",\"text\",\"n_tokens\",\"document_ids\"])\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d038114-0714-48ee-a48a-c421cd539661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'labels_added': 968, 'relationships_created': 968, 'nodes_created': 968, 'properties_set': 2904}\n",
      "968 rows processed in 1.003819227218628 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Chunk__ {id:value.id})\n",
    "SET c += value {.text, .n_tokens}\n",
    "WITH c, value\n",
    "UNWIND value.document_ids AS document\n",
    "MATCH (d:__Document__ {id:document})\n",
    "MERGE (c)-[:PART_OF]->(d)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c614c5f-6925-4237-a1bf-6ebd35dcea38",
   "metadata": {},
   "source": [
    "### Loading Nodes\n",
    "For the nodes we store id, name, description, embedding (if available), human readable id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e713603-c508-4964-ba49-474e4867b747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>id</th>\n",
       "      <th>description_embedding</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS2AGINCL6:SB</td>\n",
       "      <td>FINAL SYNTHESIZED PRODUCT</td>\n",
       "      <td>Cesium silver indium chloride doped with antim...</td>\n",
       "      <td>0</td>\n",
       "      <td>039e68fa67444c90aefca8cfbe210b8b</td>\n",
       "      <td>[0.01675415, -0.009048462, -0.02154541, 0.0342...</td>\n",
       "      <td>[a3e265300541958c6b4b8ccd864688b5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS2AGINCL6:SB,YB</td>\n",
       "      <td>FINAL SYNTHESIZED PRODUCT</td>\n",
       "      <td>Cesium silver indium chloride co-doped with an...</td>\n",
       "      <td>1</td>\n",
       "      <td>550131f8da414dc8b37cd532e31bc8b0</td>\n",
       "      <td>[0.02394104, -0.0068206787, -0.021896362, 0.03...</td>\n",
       "      <td>[a3e265300541958c6b4b8ccd864688b5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                       type  \\\n",
       "0     CS2AGINCL6:SB  FINAL SYNTHESIZED PRODUCT   \n",
       "1  CS2AGINCL6:SB,YB  FINAL SYNTHESIZED PRODUCT   \n",
       "\n",
       "                                         description  human_readable_id  \\\n",
       "0  Cesium silver indium chloride doped with antim...                  0   \n",
       "1  Cesium silver indium chloride co-doped with an...                  1   \n",
       "\n",
       "                                 id  \\\n",
       "0  039e68fa67444c90aefca8cfbe210b8b   \n",
       "1  550131f8da414dc8b37cd532e31bc8b0   \n",
       "\n",
       "                               description_embedding  \\\n",
       "0  [0.01675415, -0.009048462, -0.02154541, 0.0342...   \n",
       "1  [0.02394104, -0.0068206787, -0.021896362, 0.03...   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [a3e265300541958c6b4b8ccd864688b5]  \n",
       "1  [a3e265300541958c6b4b8ccd864688b5]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_entities.parquet',\n",
    "                            columns=[\"name\",\"type\",\"description\",\"human_readable_id\",\"id\",\"description_embedding\",\"text_unit_ids\"])\n",
    "\n",
    "# 去重，根据特定列，假设 'id' 是唯一的\n",
    "entity_df = entity_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# 检查 'name' 是否满足唯一约束，去重处理\n",
    "if 'name' in entity_df.columns:\n",
    "    entity_df = entity_df.drop_duplicates(subset=['name'])\n",
    "\n",
    "entity_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27900c01-89e1-4dec-9d5c-c07317c68baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'labels_added': 1000, 'relationships_created': 2536, 'nodes_created': 1000, 'properties_set': 4000}\n",
      "Batch 2 processed, counters: {'_contains_updates': True, 'labels_added': 1000, 'relationships_created': 1479, 'nodes_created': 1000, 'properties_set': 4000}\n",
      "Batch 3 processed, counters: {'_contains_updates': True, 'labels_added': 1000, 'relationships_created': 1196, 'nodes_created': 1000, 'properties_set': 4000}\n",
      "Batch 4 processed, counters: {'_contains_updates': True, 'labels_added': 1000, 'relationships_created': 1096, 'nodes_created': 1000, 'properties_set': 4000}\n",
      "Batch 5 processed, counters: {'_contains_updates': True, 'labels_added': 923, 'relationships_created': 974, 'nodes_created': 923, 'properties_set': 3692}\n",
      "4923 rows processed in 25.526809453964233 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4923"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity_statement = \"\"\"\n",
    "# MERGE (e:__Entity__ {id:value.id})\n",
    "# SET e += value {.human_readable_id, .description, name:replace(value.name,'\"','')}\n",
    "# WITH e, value\n",
    "# CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "# CALL apoc.create.addLabels(e, case when coalesce(value.type,\"\") = \"\" then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "# UNWIND value.text_unit_ids AS text_unit\n",
    "# MATCH (c:__Chunk__ {id:text_unit})\n",
    "# MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "# \"\"\"\n",
    "\n",
    "# batched_import(entity_statement, entity_df)\n",
    "\n",
    "entity_statement = \"\"\"\n",
    "MERGE (e:__Entity__ {id:value.id})\n",
    "ON CREATE SET e.name = replace(value.name,'\"',''),\n",
    "              e.human_readable_id = value.human_readable_id,\n",
    "              e.description = value.description\n",
    "ON MATCH SET e.human_readable_id = value.human_readable_id,\n",
    "              e.description = value.description\n",
    "WITH e, value\n",
    "CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "WITH e, value\n",
    "CALL apoc.create.addLabels(e, \n",
    "    CASE \n",
    "        WHEN coalesce(value.type, \"\") = \"\" THEN [] \n",
    "        ELSE [apoc.text.upperCamelCase(replace(value.type, '\"', ''))] \n",
    "    END) YIELD node\n",
    "UNWIND value.text_unit_ids AS text_unit\n",
    "MATCH (c:__Chunk__ {id:text_unit})\n",
    "MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(entity_statement, entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f7ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_statement = \"\"\"\n",
    "# MERGE (e:__Entity__ {id:value.id})\n",
    "# SET e.human_readable_id = value.human_readable_id,\n",
    "#     e.description = value.description,\n",
    "#     e.name = replace(value.name,'\"','')\n",
    "# WITH e, value\n",
    "# CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "# WITH e, value\n",
    "# CALL apoc.create.addLabels(e, \n",
    "#     CASE \n",
    "#         WHEN coalesce(value.type, \"\") = \"\" THEN [] \n",
    "#         ELSE [apoc.text.upperCamelCase(replace(value.type, '\"', ''))] \n",
    "#     END) YIELD node\n",
    "# UNWIND value.text_unit_ids AS text_unit\n",
    "# MATCH (c:__Chunk__ {id:text_unit})\n",
    "# MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "# \"\"\"\n",
    "\n",
    "# batched_import(entity_statement, entity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e1dd1-06ab-4741-9f5c-f1c7fb8f8bac",
   "metadata": {},
   "source": [
    "### Import Relationships\n",
    "For the relationships we find the source and target node by name, using the base `__Entity__` type. After creating the RELATED relationships, we set the description as attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1be9e7a9-69ee-406b-bce5-95a9c41ecffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS2AGINCL6:SB</td>\n",
       "      <td>WARM WHITE-LED</td>\n",
       "      <td>6508b3fe0522487da99b64fc2726d1a7</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cs2AgInCl6:Sb is used to create warm white-LEDs</td>\n",
       "      <td>[a3e265300541958c6b4b8ccd864688b5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS2AGINCL6:SB</td>\n",
       "      <td>UV CHIP</td>\n",
       "      <td>55a84a0c0471424fa430fcf8331f0010</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>UV chip is used to pump Cs2AgInCl6:Sb</td>\n",
       "      <td>[a3e265300541958c6b4b8ccd864688b5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source          target                                id  rank  \\\n",
       "0  CS2AGINCL6:SB  WARM WHITE-LED  6508b3fe0522487da99b64fc2726d1a7    15   \n",
       "1  CS2AGINCL6:SB         UV CHIP  55a84a0c0471424fa430fcf8331f0010    10   \n",
       "\n",
       "   weight human_readable_id                                      description  \\\n",
       "0     5.0                 0  Cs2AgInCl6:Sb is used to create warm white-LEDs   \n",
       "1     4.0                 1            UV chip is used to pump Cs2AgInCl6:Sb   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [a3e265300541958c6b4b8ccd864688b5]  \n",
       "1  [a3e265300541958c6b4b8ccd864688b5]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_relationships.parquet',\n",
    "                         columns=[\"source\",\"target\",\"id\",\"rank\",\"weight\",\"human_readable_id\",\"description\",\"text_unit_ids\"])\n",
    "rel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c6ed591-f98c-4403-9fde-8d4cb4c01cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'relationships_created': 1000, 'properties_set': 6000}\n",
      "Batch 2 processed, counters: {'_contains_updates': True, 'relationships_created': 1000, 'properties_set': 6000}\n",
      "Batch 3 processed, counters: {'_contains_updates': True, 'relationships_created': 1000, 'properties_set': 6000}\n",
      "Batch 4 processed, counters: {'_contains_updates': True, 'relationships_created': 467, 'properties_set': 2802}\n",
      "3467 rows processed in 1.0521461963653564 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3467"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_statement = \"\"\"\n",
    "    MATCH (source:__Entity__ {name:replace(value.source,'\"','')})\n",
    "    MATCH (target:__Entity__ {name:replace(value.target,'\"','')})\n",
    "    // not necessary to merge on id as there is only one relationship per pair\n",
    "    MERGE (source)-[rel:RELATED {id: value.id}]->(target)\n",
    "    SET rel += value {.rank, .weight, .human_readable_id, .description, .text_unit_ids}\n",
    "    RETURN count(*) as createdRels\n",
    "\"\"\"\n",
    "\n",
    "batched_import(rel_statement, rel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d02faf-b305-44c0-9cba-7328d61b833d",
   "metadata": {},
   "source": [
    "### Importing Communities\n",
    "For communities we import their id, title, level. We connect the `__Community__` nodes to the start and end nodes of the relationships they refer to.\n",
    "\n",
    "Connecting them to the chunks they orignate from is optional, as the entites are already connected to the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523bed92-d12c-4fc4-aa44-6c62321b36bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 11</td>\n",
       "      <td>[a3e265300541958c6b4b8ccd864688b5, 133f0e027ee...</td>\n",
       "      <td>[6508b3fe0522487da99b64fc2726d1a7, 55a84a0c047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 4</td>\n",
       "      <td>[59bf230c16c9b748130643fa41c6cb7d,a3e265300541...</td>\n",
       "      <td>[162830008a1e4d91a122539aa73c8d65, 66d02d4cec0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level         title                                      text_unit_ids  \\\n",
       "0  11      0  Community 11  [a3e265300541958c6b4b8ccd864688b5, 133f0e027ee...   \n",
       "1   4      0   Community 4  [59bf230c16c9b748130643fa41c6cb7d,a3e265300541...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [6508b3fe0522487da99b64fc2726d1a7, 55a84a0c047...  \n",
       "1  [162830008a1e4d91a122539aa73c8d65, 66d02d4cec0...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_communities.parquet', \n",
    "                     columns=[\"id\",\"level\",\"title\",\"text_unit_ids\",\"relationship_ids\"])\n",
    "\n",
    "community_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e064234-5fce-448e-8bb4-ab2f35699049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'labels_added': 162, 'relationships_created': 4966, 'nodes_created': 162, 'properties_set': 486}\n",
      "162 rows processed in 10.953670978546143 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.id})\n",
    "SET c += value {.level, .title}\n",
    "/*\n",
    "UNWIND value.text_unit_ids as text_unit_id\n",
    "MATCH (t:__Chunk__ {id:text_unit_id})\n",
    "MERGE (c)-[:HAS_CHUNK]->(t)\n",
    "WITH distinct c, value\n",
    "*/\n",
    "WITH *\n",
    "UNWIND value.relationship_ids as rel_id\n",
    "MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)\n",
    "MERGE (start)-[:IN_COMMUNITY]->(c)\n",
    "MERGE (end)-[:IN_COMMUNITY]->(c)\n",
    "RETURN count(distinct c) as createdCommunities\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, community_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27325cd-6ba8-43b4-8781-f9a81af5e242",
   "metadata": {},
   "source": [
    "### Importing Community Reports\n",
    "Fo the community reports we create nodes for each communitiy set the id, community, level, title, summary, rank, and rank_explanation and connect them to the entities they are about. For the findings we create the findings in context of the communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc9f6606-0cce-4f28-9d88-eaf894d8110b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>community</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3edb7330-f454-41bf-8dfa-cb7fa97334d2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Natural Light and Visible Camera Interaction</td>\n",
       "      <td>This community focuses on the interaction betw...</td>\n",
       "      <td>[{'explanation': 'The community has identified...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The rating reflects the moderate relevance of ...</td>\n",
       "      <td># Natural Light and Visible Camera Interaction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b76236e6-e529-4e9f-a7f9-ead069b759cd</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>SNO Transistor Synthesis and Performance Analysis</td>\n",
       "      <td>This community is centered around the synthesi...</td>\n",
       "      <td>[{'explanation': 'Silicon dioxide (SiO2) plays...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>The high rating is due to the comprehensive na...</td>\n",
       "      <td># SNO Transistor Synthesis and Performance Ana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id community  level  \\\n",
       "0  3edb7330-f454-41bf-8dfa-cb7fa97334d2       100      1   \n",
       "1  b76236e6-e529-4e9f-a7f9-ead069b759cd       101      1   \n",
       "\n",
       "                                               title  \\\n",
       "0       Natural Light and Visible Camera Interaction   \n",
       "1  SNO Transistor Synthesis and Performance Analysis   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This community focuses on the interaction betw...   \n",
       "1  This community is centered around the synthesi...   \n",
       "\n",
       "                                            findings  rank  \\\n",
       "0  [{'explanation': 'The community has identified...   4.5   \n",
       "1  [{'explanation': 'Silicon dioxide (SiO2) plays...   9.2   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The rating reflects the moderate relevance of ...   \n",
       "1  The high rating is due to the comprehensive na...   \n",
       "\n",
       "                                        full_content  \n",
       "0  # Natural Light and Visible Camera Interaction...  \n",
       "1  # SNO Transistor Synthesis and Performance Ana...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_report_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_community_reports.parquet',\n",
    "                               columns=[\"id\",\"community\",\"level\",\"title\",\"summary\", \"findings\",\"rank\",\"rank_explanation\",\"full_content\"])\n",
    "community_report_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47bb6f5c-4c1c-4849-8f1a-cb76fa98b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed, counters: {'_contains_updates': True, 'labels_added': 830, 'relationships_created': 830, 'nodes_created': 830, 'properties_set': 3408}\n",
      "153 rows processed in 0.311781644821167 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import communities\n",
    "community_statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.community})\n",
    "SET c += value {.level, .title, .rank, .rank_explanation, .full_content, .summary}\n",
    "WITH c, value\n",
    "UNWIND range(0, size(value.findings)-1) AS finding_idx\n",
    "WITH c, value, finding_idx, value.findings[finding_idx] as finding\n",
    "MERGE (c)-[:HAS_FINDING]->(f:Finding {id:finding_idx})\n",
    "SET f += finding\n",
    "\"\"\"\n",
    "batched_import(community_statement, community_report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44990c84-a2a8-4f1a-b758-fe1c1a02766f",
   "metadata": {},
   "source": [
    "### Importing Covariates\n",
    "Covariates are for instance claims on entities, we connect them to the chunks where they originate from.\n",
    "\n",
    "**By default, covariates are not included in the output, so the file might not exists in your output if you didn't set the configuration to extract claims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7131f3a0-2b71-4017-9dcd-24913d964dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# cov_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_covariates.parquet')\\n# cov_df.head(2)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# cov_df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_covariates.parquet')\n",
    "# cov_df.head(2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0d2a7dc-8885-41f0-b971-39628d08b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_statement = \"\"\"\n",
    "MERGE (c:__Covariate__ {id:value.id})\n",
    "SET c += apoc.map.clean(value, [\"text_unit_id\", \"document_ids\", \"n_tokens\"], [NULL, \"\"])\n",
    "WITH c, value\n",
    "MATCH (ch:__Chunk__ {id: value.text_unit_id})\n",
    "MERGE (ch)-[:HAS_COVARIATE]->(c)\n",
    "\"\"\"\n",
    "# batched_import(cov_statement, cov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bee996-44dd-41c4-a594-5cdec45e80fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
